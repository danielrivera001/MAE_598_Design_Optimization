{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b716f15",
   "metadata": {},
   "source": [
    "# Project 1: Gradient-based Algorithms and Differentiable Programming\n",
    "## By: Daniel Rivera | MAE 598: Design Optimization\n",
    "## Prof. Max Yi Ren | Fall 2022\n",
    "#### This optimization problem involves the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fecb433",
   "metadata": {},
   "source": [
    "$$ d(t+1) = d(t) +v(t)\\Delta t$$\n",
    "$$ v(t+1) =v(t) + a(t)\\Delta t$$ \n",
    "#### and\n",
    "$$ a(t) = f_{theta}(x(t)) $$\n",
    "\n",
    "#### where d is the distance from the ground at any given time, v is the velocity at any given time, a is the acceleration at any given time and f is a neural network that has $$ \\theta $$ as a parameter. Our goal is to optimize this formulation of a rocket landing through the utilization of all of the aformentioned formulas. The optimization problem is as follows: \n",
    "\n",
    "$$ min_{\\theta} \\begin{Vmatrix} x(T) \\end{Vmatrix}^2 $$\n",
    "$$ d(t+1) = d(t) +v(t)\\Delta t$$\n",
    "$$ v(t+1) =v(t) + a(t)\\Delta t$$ \n",
    "$$ a(t) = f_{\\theta}(x(t)), \\forall t=1,...,T-1 $$\n",
    "\n",
    "### Implementing Drag into the code\n",
    "#### We can make this rocket-landing problem more realistic by adding a variable called drag, which is an opposing force that an aircraft's wings experience in flight and especially when landing. This force is defined mathematically as:\n",
    "\n",
    "$$ F_{D}=\\frac{C_{D}\\rho V^{2}A}{2} $$\n",
    "\n",
    "#### Where we then simplify the Variable Drag even further as \n",
    "\n",
    "$$ Drag= \\frac{C_{D}V^{2}}{2} $$\n",
    "\n",
    "#### Then our new optimization problem becomes:\n",
    "\n",
    "$$ min_{\\theta}(Drag,\\Delta Drag, x(\\theta))\\begin{Vmatrix}x(T)\\end{Vmatrix}^2 $$\n",
    "$$ d(t+1) = d(t) +v(t)+Drag\\Delta t$$\n",
    "$$ v(t+1) =v(t) + a(t)+Drag\\Delta t$$ \n",
    "$$ a(t) = f_{\\theta}(x(t)), \\forall t=1,...,T-1 $$\n",
    "#### Let us just take a sample of 30 points of state:\n",
    "$$ min_(\\Theta)1/30\\sum\\limits_{i=1}^{30}(x^(i)(T))^2\n",
    "\n",
    "\n",
    "\n",
    "#### Thus we've established an uncontrained problem with respect to theta.With that being said, we are able to make slight adjustments to the provided python script in order to determine solutions to this optimization problem. Several python libraries including pytortch and matplot lib are heavily utilized in order to simplify the coding. Furthermore, the matplot library is used in order to provide graphical representation of the solutions.Comments of each step within the code are provided along with a better problem formulation, and an analysis of findings at the end. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "93a0173b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import all of the necessary libraries \n",
    "# overhead\n",
    "\n",
    "import logging\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import time\n",
    "import torch as t\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.nn import utils\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0f2d0765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# environment parameters including the time interval, \n",
    "#and various accelerations\n",
    "\n",
    "FRAME_TIME = 0.1  # time interval\n",
    "GRAVITY_ACCEL = 0.12  # gravity constant\n",
    "BOOST_ACCEL = 0.18  # thrust constant\n",
    "DRAG_ACCEL = .06\n",
    "# # the following parameters are not being used in the sample code\n",
    "# PLATFORM_WIDTH = 0.25  # landing platform width\n",
    "# PLATFORM_HEIGHT = 0.06  # landing platform height\n",
    "# ROTATION_ACCEL = 20  # rotation constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e18859fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define system dynamics\n",
    "# Notes: \n",
    "# 0. You only need to modify the \"forward\" function\n",
    "# 1. All variables in \"forward\" need to be PyTorch tensors.\n",
    "# 2. All math operations in \"forward\" has to be differentiable, e.g., default PyTorch functions.\n",
    "# 3. Do not use inplace operations, e.g., x += 1. Please see the following section for an example that does not work.\n",
    "\n",
    "class Dynamics(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Dynamics, self).__init__()\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(state, action):\n",
    "\n",
    "        \"\"\"\n",
    "        action: thrust or no thrust\n",
    "        state[0] = y\n",
    "        state[1] = y_dot\n",
    "        \"\"\"\n",
    "        \n",
    "        # Apply gravity\n",
    "        # Note: Here gravity is used to change velocity which is the second element of the state vector\n",
    "        # Normally, we would do x[1] = x[1] + gravity * delta_time\n",
    "        # but this is not allowed in PyTorch since it overwrites one variable (x[1]) that is part of the computational graph to be differentiated.\n",
    "        # Therefore, I define a tensor dx = [0., gravity * delta_time], and do x = x + dx. This is allowed... \n",
    "        delta_state_gravity = t.tensor([0., GRAVITY_ACCEL * FRAME_TIME])\n",
    "\n",
    "        # Thrust\n",
    "        # Note: Same reason as above. Need a 2-by-1 tensor.\n",
    "        delta_stateT = BOOST_ACCEL * FRAME_TIME * t.tensor([0., -1.]) * action\n",
    "        \n",
    "        # Drag\n",
    "        delta_stateD = state * DRAG_ACCEL * FRAME_TIME * t.tensor([0., 1.]) * action\n",
    "        \n",
    "        delta_state = delta_stateT + delta_stateD\n",
    "        \n",
    "        # Update velocity\n",
    "        state = state + delta_state + delta_state_gravity \n",
    "        \n",
    "        # Update state\n",
    "        # Note: Same as above. Use operators on matrices/tensors as much as possible. Do not use element-wise operators as they are considered inplace.\n",
    "        step_mat = t.tensor([[1., FRAME_TIME],\n",
    "                            [0., 1.]])\n",
    "        state = t.matmul(step_mat, state)\n",
    "\n",
    "        return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "327231de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding third dimension work and progress\n",
    "class Dynamics(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Dynamics, self).__init__()\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(state, action):\n",
    "\n",
    "       \n",
    "        delta_state_gravity = t.tensor([0., GRAVITY_ACCEL * FRAME_TIME, 0.])\n",
    "\n",
    "        # Thrust\n",
    "        # Note: Same reason as above. Need a 2-by-1 tensor.\n",
    "        delta_stateT = BOOST_ACCEL * FRAME_TIME * t.tensor([0., -1., 0.]) * action\n",
    "        \n",
    "        # Drag\n",
    "        delta_stateD = state * DRAG_ACCEL * FRAME_TIME * t.tensor([0., 0., 1]) * action\n",
    "        \n",
    "        #delta_state = delta_stateT - delta_stateD\n",
    "        \n",
    "        # Update velocity\n",
    "        state = state + delta_stateT + delta_state_gravity + delta_stateD\n",
    "        \n",
    "        # Update state\n",
    "        # Note: Same as above. Use operators on matrices/tensors as much as possible. Do not use element-wise operators as they are considered inplace.\n",
    "        step_mat = t.tensor([[1., FRAME_TIME, 1.],\n",
    "                            [0., 1., 0.]])\n",
    "        state = t.matmul(step_mat, state)\n",
    "\n",
    "        return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "31c8459d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a deterministic controller\n",
    "# Note:\n",
    "# 0. You only need to change the network architecture in \"__init__\"\n",
    "# 1. nn.Sigmoid outputs values from 0 to 1, nn.Tanh from -1 to 1\n",
    "# 2. You have all the freedom to make the network wider (by increasing \"dim_hidden\") or deeper (by adding more lines to nn.Sequential)\n",
    "# 3. Always start with something simple\n",
    "#t.transpose(xthrust_t.unsqueeze(0),0,1)\n",
    "\n",
    "class Controller(nn.Module):\n",
    "\n",
    "    def __init__(self, dim_input, dim_hidden, dim_output):\n",
    "        \"\"\"\n",
    "        dim_input: # of system states\n",
    "        dim_output: # of actions\n",
    "        dim_hidden: up to you\n",
    "        \"\"\"\n",
    "        super(Controller, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(dim_input, dim_hidden),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(dim_hidden, dim_output),\n",
    "            # You can add more layers here\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "#nn.Flatten()\n",
    "    def forward(self, state):\n",
    "        action = self.network(state)\n",
    "        return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "522ec026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the simulator that rolls out x(1), x(2), ..., x(T)\n",
    "# Note:\n",
    "# 0. Need to change \"initialize_state\" to optimize the controller over a distribution of initial states\n",
    "# 1. self.action_trajectory and self.state_trajectory stores the action and state trajectories along time\n",
    "\n",
    "class Simulation(nn.Module):\n",
    "\n",
    "    def __init__(self, controller, dynamics, T):\n",
    "        super(Simulation, self).__init__()\n",
    "        self.state = self.initialize_state()\n",
    "        self.controller = controller\n",
    "        self.dynamics = dynamics\n",
    "        self.T = T \n",
    "        self.action_trajectory = []\n",
    "        self.state_trajectory = []\n",
    "\n",
    "    def forward(self, state):\n",
    "        self.action_trajectory = []\n",
    "        self.state_trajectory = []\n",
    "        for _ in range(T):\n",
    "            action = self.controller.forward(state)\n",
    "            state = self.dynamics.forward(state, action)\n",
    "            self.action_trajectory.append(action)\n",
    "            self.state_trajectory.append(state)\n",
    "        return self.error(state)\n",
    "\n",
    "    @staticmethod\n",
    "    def initialize_state():\n",
    "        state = [1., 0.] \n",
    "        return t.tensor(state, requires_grad=False).float()\n",
    "\n",
    "# For the second column of the state function there were several values that were tested. As the number increased into the real \n",
    "# whole number the loss increases exponentially.\n",
    "# Values tested 0, 1, 2, 3, 4, 5, 6,\n",
    "\n",
    "    def error(self, state):\n",
    "        return state[0]**2 + state[1]**2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "97d75304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the optimizer\n",
    "# Note:\n",
    "# 0. LBFGS is a good choice if you don't have a large batch size (i.e., a lot of initial states to consider simultaneously)\n",
    "# 1. You can also try SGD and other momentum-based methods implemented in PyTorch\n",
    "# 2. You will need to customize \"visualize\"\n",
    "# 3. loss.backward is where the gradient is calculated (d_loss/d_variables)\n",
    "# 4. self.optimizer.step(closure) is where gradient descent is done\n",
    "\n",
    "class Optimize:\n",
    "    def __init__(self, simulation):\n",
    "        self.simulation = simulation\n",
    "        self.parameters = simulation.controller.parameters()\n",
    "        self.optimizer = optim.LBFGS(self.parameters, lr=0.01)\n",
    "\n",
    "    def step(self):\n",
    "        def closure():\n",
    "            loss = self.simulation(self.simulation.state)\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            return loss\n",
    "        self.optimizer.step(closure)\n",
    "        return closure()\n",
    "    \n",
    "    def train(self, epochs):\n",
    "        L = []\n",
    "        for epoch in range(epochs):\n",
    "            loss = self.step()\n",
    "            L.append(loss)\n",
    "            print('[%d] loss: %.3f' % (epoch + 1, loss))\n",
    "            self.visualize()\n",
    "        return L\n",
    "\n",
    "    def visualize(self):\n",
    "    \n",
    "    # Loss vs iteration\n",
    "        data = np.array([self.simulation.state_trajectory[i].detach().numpy() for i in range(self.simulation.T)])\n",
    "        x = data[:, 0]\n",
    "        y = data[:, 1]\n",
    "        plt.plot(x, y)\n",
    "        plt.show()\n",
    "        plt.title('Loss vs Iteration')\n",
    "        plt.xlabel('Iteration')\n",
    "        plt.ylabel('Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c3f3b103",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (3) must match the size of tensor b (2) at non-singleton dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [23]\u001b[0m, in \u001b[0;36m<cell line: 11>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m s \u001b[38;5;241m=\u001b[39m Simulation(c, d, T)  \u001b[38;5;66;03m# define simulation\u001b[39;00m\n\u001b[0;32m     10\u001b[0m o \u001b[38;5;241m=\u001b[39m Optimize(s)  \u001b[38;5;66;03m# define optimizer\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m \u001b[43mo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m40\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [22]\u001b[0m, in \u001b[0;36mOptimize.train\u001b[1;34m(self, epochs)\u001b[0m\n\u001b[0;32m     25\u001b[0m L \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m---> 27\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m     L\u001b[38;5;241m.\u001b[39mappend(loss)\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m] loss: \u001b[39m\u001b[38;5;132;01m%.3f\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, loss))\n",
      "Input \u001b[1;32mIn [22]\u001b[0m, in \u001b[0;36mOptimize.step\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     19\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m closure()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Design_Optimization_Scripts\\lib\\site-packages\\torch\\optim\\optimizer.py:88\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m profile_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimizer.step#\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.step\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(obj\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mrecord_function(profile_name):\n\u001b[1;32m---> 88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Design_Optimization_Scripts\\lib\\site-packages\\torch\\autograd\\grad_mode.py:28\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m():\n\u001b[1;32m---> 28\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Design_Optimization_Scripts\\lib\\site-packages\\torch\\optim\\lbfgs.py:311\u001b[0m, in \u001b[0;36mLBFGS.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    308\u001b[0m state\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_iter\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    310\u001b[0m \u001b[38;5;66;03m# evaluate initial f(x) and df/dx\u001b[39;00m\n\u001b[1;32m--> 311\u001b[0m orig_loss \u001b[38;5;241m=\u001b[39m \u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    312\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(orig_loss)\n\u001b[0;32m    313\u001b[0m current_evals \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Design_Optimization_Scripts\\lib\\site-packages\\torch\\autograd\\grad_mode.py:28\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m():\n\u001b[1;32m---> 28\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "Input \u001b[1;32mIn [22]\u001b[0m, in \u001b[0;36mOptimize.step.<locals>.closure\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclosure\u001b[39m():\n\u001b[1;32m---> 17\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimulation\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimulation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     19\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Design_Optimization_Scripts\\lib\\site-packages\\torch\\nn\\modules\\module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[1;32mIn [21]\u001b[0m, in \u001b[0;36mSimulation.forward\u001b[1;34m(self, state)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(T):\n\u001b[0;32m     21\u001b[0m     action \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontroller\u001b[38;5;241m.\u001b[39mforward(state)\n\u001b[1;32m---> 22\u001b[0m     state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdynamics\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_trajectory\u001b[38;5;241m.\u001b[39mappend(action)\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate_trajectory\u001b[38;5;241m.\u001b[39mappend(state)\n",
      "Input \u001b[1;32mIn [19]\u001b[0m, in \u001b[0;36mDynamics.forward\u001b[1;34m(state, action)\u001b[0m\n\u001b[0;32m     11\u001b[0m delta_state_gravity \u001b[38;5;241m=\u001b[39m t\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;241m0.\u001b[39m, GRAVITY_ACCEL \u001b[38;5;241m*\u001b[39m FRAME_TIME, \u001b[38;5;241m0.\u001b[39m])\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Thrust\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Note: Same reason as above. Need a 2-by-1 tensor.\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m delta_stateT \u001b[38;5;241m=\u001b[39m \u001b[43mBOOST_ACCEL\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mFRAME_TIME\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0.\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1.\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43maction\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Drag\u001b[39;00m\n\u001b[0;32m     18\u001b[0m delta_stateD \u001b[38;5;241m=\u001b[39m state \u001b[38;5;241m*\u001b[39m DRAG_ACCEL \u001b[38;5;241m*\u001b[39m FRAME_TIME \u001b[38;5;241m*\u001b[39m t\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;241m0.\u001b[39m, \u001b[38;5;241m0.\u001b[39m, \u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m*\u001b[39m action\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (3) must match the size of tensor b (2) at non-singleton dimension 0"
     ]
    }
   ],
   "source": [
    "# Now it's time to run the code!\n",
    "\n",
    "T = 100  # number of time steps\n",
    "dim_input = 2  # state space dimensions\n",
    "dim_hidden = 8  # latent dimensions\n",
    "dim_output = 2  # action space dimensions\n",
    "d = Dynamics()  # define dynamics\n",
    "c = Controller(dim_input, dim_hidden, dim_output)  # define controller\n",
    "s = Simulation(c, d, T)  # define simulation\n",
    "o = Optimize(s)  # define optimizer\n",
    "o.train(40)  # solve the optimization problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38515645",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
